# Day17(3.2)

### 1.梯度下降法(迭代法)求解

- 核心思想：通过迭代更新模型参数，使得损失函数逐步减小，最终找到最优解
- 步骤：
  - 1.初始化参数：给权重w，偏置b赋初值
  - 2.计算梯度：根据当前参数，计算损失函数对每个参数的偏导数(梯度)![](https://winterhoildayaixly.oss-cn-shenzhen.aliyuncs.com/image-20260228162021257.png)
  - 3.更新参数：沿着梯度反方向更新参数![image-20260228162124562](https://winterhoildayaixly.oss-cn-shenzhen.aliyuncs.com/image-20260228162124562.png)
  - 4.迭代收敛：重复步骤23，直到损失函数变化很小或达到最大迭代次数
- 特点：
  - 适用于数据量极大，特征维度高（非线性），无法直接**解析解（公式法）**（线性）的场景
  - 需要手动调整学习率，迭代次数等超参数
  - 可以通过小批量梯度下降等提高整体效率

### 2.解析求解

#### 最小二乘法构建损失函数：

- 最小二乘是目标，即损失最小，解析法和梯度下降法是达成此目标的方法
- 核心思想：最小化预测值与真实值之间的误差平方和，通过矩阵求导直接求出参数的闭式解
- 损失函数：![image-20260228163130635](https://winterhoildayaixly.oss-cn-shenzhen.aliyuncs.com/image-20260228163130635.png)
- 矩阵形式：![image-20260228163208929](https://winterhoildayaixly.oss-cn-shenzhen.aliyuncs.com/image-20260228163208929.png)
- 求解过程：![image-20260228163227268](https://winterhoildayaixly.oss-cn-shenzhen.aliyuncs.com/image-20260228163227268.png)
- 特点：
  - 一次计算即可得到全局最优
  - 适用数据量和维度都适中的情况，当特征维度过大或矩阵不可逆，计算代价极高或无法求解

